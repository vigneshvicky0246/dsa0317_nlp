DESCRIPTION:
The code implements a basic information retrieval system using TF-IDF (Term Frequency-Inverse Document Frequency) to rank 
documents based on their relevance to a given query. 
The TF-IDF score is used to evaluate the importance of words within a document relative to a collection of documents. 
The cosine similarity measure is used to rank the documents based on their similarity to the query.

CODE:
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# List of documents
documents = [
    "TF-IDF, or term frequency-inverse document frequency, is a statistic that evaluates the importance of a word in a document relative to a collection of documents.",
    "It is often used in information retrieval and text mining.",
    "The TF-IDF score increases with the frequency of the word in the document and is offset by the frequency of the word in the entire collection of documents.",
    "In other words, TF-IDF highlights words that are unique to a document and are not common across many documents.",
    "To implement TF-IDF, you need to calculate the term frequency and inverse document frequency for each word in the document collection.",
]
query = "TF-IDF in information retrieval"
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(documents + [query])
cosine_similarities = linear_kernel(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()
document_ranking = sorted(enumerate(cosine_similarities), key=lambda x: x[1], reverse=True)
print("Ranked Documents:")
for idx, similarity in document_ranking:
    print(f"Document {idx + 1}: Similarity = {similarity:.4f}")
    print(f"   {documents[idx]}")
    print()

OUTPUT:
Ranked Documents:
Document 1: Similarity = 0.3652
   TF-IDF, or term frequency-inverse document frequency, is a statistic that evaluates the importance of a word in a document relative to a collection of documents.

Document 3: Similarity = 0.3351
   The TF-IDF score increases with the frequency of the word in the document and is offset by the frequency of the word in the entire collection of documents.

Document 5: Similarity = 0.2577
   To implement TF-IDF, you need to calculate the term frequency and inverse document frequency for each word in the document collection.

Document 4: Similarity = 0.2407
   In other words, TF-IDF highlights words that are unique to a document and are not common across many documents.

Document 2: Similarity = 0.1453
   It is often used in information retrieval and text mining.
